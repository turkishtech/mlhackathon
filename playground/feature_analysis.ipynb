{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T13:57:54.081867Z",
     "start_time": "2018-01-29T13:57:53.452432Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T13:57:54.306307Z",
     "start_time": "2018-01-29T13:57:54.083996Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=4,suppress=True)\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T13:57:54.740469Z",
     "start_time": "2018-01-29T13:57:54.308597Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T13:57:54.746008Z",
     "start_time": "2018-01-29T13:57:54.742929Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T13:57:56.767180Z",
     "start_time": "2018-01-29T13:57:54.748663Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('de', disable=['parser', 'tagger'])\n",
    "# FOR FastText vectors\n",
    "# nlp.vocab.from_disk('./vocab/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T13:57:56.821274Z",
     "start_time": "2018-01-29T13:57:56.769934Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "GRUBER_URLINTEXT_PAT = re.compile(r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?\\xab\\xbb\\u201c\\u201d\\u2018\\u2019]))')\n",
    "NUMBER_CLEAN = re.compile(r'\\d+(:?[.,]?\\d+)*')\n",
    "TIME_CLEAN = re.compile(r'\\d+:\\d+(?:\\s?[Uu]hr)?')\n",
    "\n",
    "def preprocessing(text):\n",
    "    try:\n",
    "        # clean-up url\n",
    "        text = GRUBER_URLINTEXT_PAT.sub('url', text)\n",
    "        # remove time\n",
    "        text = TIME_CLEAN.sub('zeit', text)\n",
    "        # clean-up numbers\n",
    "        text = NUMBER_CLEAN.sub('nummer', text)\n",
    "        return text\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "preprocessing('Yeah , der WG gef√§llt deine Musik . Hol dir auch superschnelles Internet ! https://t.co/0dPArCUv0b https://t.co/HHRZaAQnte http://pbs.twimg.com/amplify_video_thumb/0123456789001234567890/img/QEQntlwB_ifYH3Gv.jpg')\n",
    "\n",
    "with open('./stopwords-de.txt') as f:\n",
    "    stopwords = f.read().split('\\n')\n",
    "    \n",
    "def filter_toks(token):\n",
    "    if token.tag_ in ['$,','$.','$(']:\n",
    "        return False\n",
    "    if token.pos_ in ['ADP']:\n",
    "        return False\n",
    "    if token.lemma_.lower() in stopwords:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T13:59:23.910937Z",
     "start_time": "2018-01-29T13:59:23.679449Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'docs.pl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-acedf885e99c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'docs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'documents'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pl'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'docs.pl'"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for file in ['docs', 'documents', 'labels', 'tags']:\n",
    "    with open(file+'.pl') as f:\n",
    "        data[file] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:19:40.510807Z",
     "start_time": "2018-01-29T12:17:53.060Z"
    }
   },
   "outputs": [],
   "source": [
    "labels[0], documents[0], docs[0], tags[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-26T14:23:41.956631Z",
     "start_time": "2018-01-26T14:23:41.954043Z"
    }
   },
   "source": [
    "# Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:19:40.512374Z",
     "start_time": "2018-01-29T12:17:53.355Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# create lemma lists filter punctuation and numbers\n",
    "# from spacy\n",
    "lemmas = [word.lemma_ for words in docs for word in words if word.pos_ not in ['PUNCT','NUM']]\n",
    "counts = Counter(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:19:40.513937Z",
     "start_time": "2018-01-29T12:17:53.642Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lemma_df = pd.DataFrame.from_dict(counts, orient='index')\n",
    "lemma_df.sort_values(by=0,ascending=False).head(50).plot(kind='bar', figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T13:29:21.615327Z",
     "start_time": "2018-01-29T13:29:21.498841Z"
    }
   },
   "outputs": [],
   "source": [
    "counts = Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:19:40.516259Z",
     "start_time": "2018-01-29T12:17:54.154Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmas = [len(words) for words in documents]\n",
    "word_counts = Counter(lemmas)\n",
    "\n",
    "lemma_df = pd.DataFrame.from_dict(word_counts, orient='index')\n",
    "a = lemma_df.sort_values(by=0,ascending=False).head(50).plot(kind='bar', figsize=(20,10))\n",
    "a.set_title('number of words per row')\n",
    "a.set_ylabel('number of rows')\n",
    "a.set_xlabel('number of words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:19:40.518420Z",
     "start_time": "2018-01-29T12:17:54.380Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmas = ([len(document) for document in documents])\n",
    "word_counts = Counter(lemmas)\n",
    "\n",
    "lemma_df = pd.DataFrame.from_dict(word_counts, orient='index')\n",
    "a = lemma_df.sort_values(by=0,ascending=False).head(50).plot(kind='bar', figsize=(20,10))\n",
    "a.set_title('number of characters per row')\n",
    "a.set_ylabel('number of rows')\n",
    "a.set_xlabel('number of words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:19:40.520644Z",
     "start_time": "2018-01-29T12:17:54.619Z"
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "cloud = WordCloud(width=1440, height=1080).generate(\" \".join([word.lemma_ for doc in docs for word in doc]))\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.imshow(cloud)\n",
    "plt.title('Most common lemmas')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:19:40.523041Z",
     "start_time": "2018-01-29T12:17:55.114Z"
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "cloud = WordCloud(width=1440, height=1080).generate(\" \".join([word.lemma_ for doc in docs for word in doc if word.lemma_.lower() not in stopwords]))\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.imshow(cloud)\n",
    "plt.title('Most common lemmas without stopwords')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:19:40.524473Z",
     "start_time": "2018-01-29T12:17:55.438Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qmarks = np.mean(df.Content.apply(lambda x: '?' in x))\n",
    "math = np.mean(df.Content.apply(lambda x: '‚Ç¨' in x))\n",
    "fullstop = np.mean(df.Content.apply(lambda x: '.' in x))\n",
    "capital_first = np.mean(df.Content.apply(lambda x: x[0].isupper()))\n",
    "capitals = np.mean(df.Content.apply(lambda x: max([y.isupper() for y in x.split(' ')])))\n",
    "numbers = np.mean(df.Content.apply(lambda x: max([y.isdigit() for y in x])))\n",
    "\n",
    "print('Rows with question marks: {:.2f}%'.format(qmarks * 100))\n",
    "print('Rows with ‚Ç¨: {:.2f}%'.format(math * 100))\n",
    "print('Rows with full stops: {:.2f}%'.format(fullstop * 100))\n",
    "print('Rows with capitalised first letters: {:.2f}%'.format(capital_first * 100))\n",
    "print('Rows with capital letters: {:.2f}%'.format(capitals * 100))\n",
    "print('Rows with numbers: {:.2f}%'.format(numbers * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RASA TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:57:13.959619Z",
     "start_time": "2018-01-29T12:57:13.692823Z"
    }
   },
   "outputs": [],
   "source": [
    "import simplejson\n",
    "fp = {\n",
    "    \"rasa_nlu_data\": {\n",
    "        \"common_examples\": [],\n",
    "        \"regex_features\" : [],\n",
    "        \"entity_synonyms\": []\n",
    "    }\n",
    "}\n",
    "fb = {\n",
    "    \"rasa_nlu_data\": {\n",
    "        \"common_examples\": [],\n",
    "        \"regex_features\" : [],\n",
    "        \"entity_synonyms\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "for i in range(len(documents)):\n",
    "    fp[\"rasa_nlu_data\"]['common_examples'].append(dict(text=documents[i], intent=tags[i], entities=[]))\n",
    "\n",
    "with open('train_prio.json', 'wt') as file_p:\n",
    "    simplejson.dump(fp, file_p)\n",
    "    \n",
    "# with open('train_bucket.json', 'w') as file_b:\n",
    "#     json.dump(fb, file_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:28:45.748780Z",
     "start_time": "2018-01-29T12:28:45.740420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{label for label in labels if type(label) is str}\n",
    "len([label for label in labels if type(label) is str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:32:33.656946Z",
     "start_time": "2018-01-29T12:32:33.651348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prio distrib.: 0.10005817335660268\n"
     ]
    }
   ],
   "source": [
    "print('prio distrib.: {}'.format(sum(tags)/len(tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:19:40.527219Z",
     "start_time": "2018-01-29T12:17:56.516Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: try different sets of stopwords (e.g. with or without kein, nicht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:26:12.488400Z",
     "start_time": "2018-01-29T12:26:12.327310Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./train_bucket.json') as f:\n",
    "    test=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:26:56.502599Z",
     "start_time": "2018-01-29T12:26:56.498610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': nan, 'text': 'Ich warte noch auf eine korrekte Rechnung !'}"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['common_examples']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:19:40.528640Z",
     "start_time": "2018-01-29T12:17:57.050Z"
    }
   },
   "outputs": [],
   "source": [
    "# wordvectors:\n",
    "w2v = [[word.vector for word in doc if word.text not in stopwords] for doc in docs]\n",
    "\n",
    "# average w2v\n",
    "X = np.array([np.mean([word.vector for word in doc if word.text not in stopwords], 0) for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T13:00:12.012001Z",
     "start_time": "2018-01-29T13:00:11.763676Z"
    }
   },
   "outputs": [],
   "source": [
    "# bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "CountVectorizer()\n",
    "BoW = CountVectorizer(documents, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T13:00:20.004270Z",
     "start_time": "2018-01-29T13:00:12.014933Z"
    }
   },
   "outputs": [],
   "source": [
    "X_bag = BoW.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T13:00:26.264511Z",
     "start_time": "2018-01-29T13:00:26.242717Z"
    }
   },
   "outputs": [],
   "source": [
    "Y = np.array(np.array(tags)=='Prio-Fall', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T13:00:37.775721Z",
     "start_time": "2018-01-29T13:00:37.754900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14504915987966835"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y)/len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T13:23:29.081202Z",
     "start_time": "2018-01-29T13:23:29.061844Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Set our parameters for xgboost\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['eta'] = 0.02\n",
    "params['max_depth'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T13:29:20.848790Z",
     "start_time": "2018-01-29T13:23:32.299263Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.681398\tvalid-logloss:0.681793\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.585418\tvalid-logloss:0.589439\n",
      "[20]\ttrain-logloss:0.516978\tvalid-logloss:0.524332\n",
      "[30]\ttrain-logloss:0.466842\tvalid-logloss:0.477235\n",
      "[40]\ttrain-logloss:0.429251\tvalid-logloss:0.442479\n",
      "[50]\ttrain-logloss:0.400655\tvalid-logloss:0.416498\n",
      "[60]\ttrain-logloss:0.378061\tvalid-logloss:0.396746\n",
      "[70]\ttrain-logloss:0.360315\tvalid-logloss:0.381628\n",
      "[80]\ttrain-logloss:0.346352\tvalid-logloss:0.370119\n",
      "[90]\ttrain-logloss:0.335163\tvalid-logloss:0.361113\n",
      "[100]\ttrain-logloss:0.326145\tvalid-logloss:0.354207\n",
      "[110]\ttrain-logloss:0.318762\tvalid-logloss:0.348827\n",
      "[120]\ttrain-logloss:0.312501\tvalid-logloss:0.344499\n",
      "[130]\ttrain-logloss:0.307515\tvalid-logloss:0.340989\n",
      "[140]\ttrain-logloss:0.303432\tvalid-logloss:0.338127\n",
      "[150]\ttrain-logloss:0.299804\tvalid-logloss:0.335769\n",
      "[160]\ttrain-logloss:0.296927\tvalid-logloss:0.333866\n",
      "[170]\ttrain-logloss:0.294363\tvalid-logloss:0.332331\n",
      "[180]\ttrain-logloss:0.292337\tvalid-logloss:0.331039\n",
      "[190]\ttrain-logloss:0.290473\tvalid-logloss:0.330011\n",
      "[200]\ttrain-logloss:0.289121\tvalid-logloss:0.329162\n",
      "[210]\ttrain-logloss:0.287666\tvalid-logloss:0.328333\n",
      "[220]\ttrain-logloss:0.286402\tvalid-logloss:0.327583\n",
      "[230]\ttrain-logloss:0.285169\tvalid-logloss:0.326954\n",
      "[240]\ttrain-logloss:0.28364\tvalid-logloss:0.326215\n",
      "[250]\ttrain-logloss:0.282323\tvalid-logloss:0.325574\n",
      "[260]\ttrain-logloss:0.281378\tvalid-logloss:0.325063\n",
      "[270]\ttrain-logloss:0.280104\tvalid-logloss:0.324488\n",
      "[280]\ttrain-logloss:0.279115\tvalid-logloss:0.324027\n",
      "[290]\ttrain-logloss:0.278386\tvalid-logloss:0.3237\n",
      "[300]\ttrain-logloss:0.27746\tvalid-logloss:0.323256\n",
      "[310]\ttrain-logloss:0.27649\tvalid-logloss:0.322805\n",
      "[320]\ttrain-logloss:0.275427\tvalid-logloss:0.322379\n",
      "[330]\ttrain-logloss:0.274685\tvalid-logloss:0.322037\n",
      "[340]\ttrain-logloss:0.273993\tvalid-logloss:0.321719\n",
      "[350]\ttrain-logloss:0.273394\tvalid-logloss:0.321449\n",
      "[360]\ttrain-logloss:0.272848\tvalid-logloss:0.321212\n",
      "[370]\ttrain-logloss:0.272089\tvalid-logloss:0.320882\n",
      "[380]\ttrain-logloss:0.271595\tvalid-logloss:0.320674\n",
      "[390]\ttrain-logloss:0.270964\tvalid-logloss:0.320403\n",
      "[399]\ttrain-logloss:0.270538\tvalid-logloss:0.320228\n",
      "f1 score: 0.2918836140888208\n",
      "accuracy: 87.27747970835053\\%\n",
      "[0]\ttrain-logloss:0.681325\tvalid-logloss:0.681758\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.584965\tvalid-logloss:0.58905\n",
      "[20]\ttrain-logloss:0.516382\tvalid-logloss:0.523832\n",
      "[30]\ttrain-logloss:0.465862\tvalid-logloss:0.476672\n",
      "[40]\ttrain-logloss:0.427879\tvalid-logloss:0.441808\n",
      "[50]\ttrain-logloss:0.398912\tvalid-logloss:0.415739\n",
      "[60]\ttrain-logloss:0.376766\tvalid-logloss:0.396306\n",
      "[70]\ttrain-logloss:0.359096\tvalid-logloss:0.381416\n",
      "[80]\ttrain-logloss:0.345337\tvalid-logloss:0.370103\n",
      "[90]\ttrain-logloss:0.333981\tvalid-logloss:0.361294\n",
      "[100]\ttrain-logloss:0.325118\tvalid-logloss:0.354439\n",
      "[110]\ttrain-logloss:0.318083\tvalid-logloss:0.349188\n",
      "[120]\ttrain-logloss:0.312076\tvalid-logloss:0.34493\n",
      "[130]\ttrain-logloss:0.306999\tvalid-logloss:0.341466\n",
      "[140]\ttrain-logloss:0.302758\tvalid-logloss:0.338662\n",
      "[150]\ttrain-logloss:0.298777\tvalid-logloss:0.336205\n",
      "[160]\ttrain-logloss:0.295551\tvalid-logloss:0.334347\n",
      "[170]\ttrain-logloss:0.292648\tvalid-logloss:0.332758\n",
      "[180]\ttrain-logloss:0.290125\tvalid-logloss:0.331286\n",
      "[190]\ttrain-logloss:0.288147\tvalid-logloss:0.33011\n",
      "[200]\ttrain-logloss:0.286522\tvalid-logloss:0.329167\n",
      "[210]\ttrain-logloss:0.285289\tvalid-logloss:0.32843\n",
      "[220]\ttrain-logloss:0.284253\tvalid-logloss:0.327863\n",
      "[230]\ttrain-logloss:0.283246\tvalid-logloss:0.327309\n",
      "[240]\ttrain-logloss:0.281806\tvalid-logloss:0.326566\n",
      "[250]\ttrain-logloss:0.280401\tvalid-logloss:0.325939\n",
      "[260]\ttrain-logloss:0.279192\tvalid-logloss:0.325364\n",
      "[270]\ttrain-logloss:0.278289\tvalid-logloss:0.324916\n",
      "[280]\ttrain-logloss:0.277331\tvalid-logloss:0.324473\n",
      "[290]\ttrain-logloss:0.27618\tvalid-logloss:0.323934\n",
      "[300]\ttrain-logloss:0.275151\tvalid-logloss:0.323483\n",
      "[310]\ttrain-logloss:0.27436\tvalid-logloss:0.32311\n",
      "[320]\ttrain-logloss:0.273291\tvalid-logloss:0.322628\n",
      "[330]\ttrain-logloss:0.272511\tvalid-logloss:0.322268\n",
      "[340]\ttrain-logloss:0.271708\tvalid-logloss:0.321909\n",
      "[350]\ttrain-logloss:0.271062\tvalid-logloss:0.321629\n",
      "[360]\ttrain-logloss:0.270384\tvalid-logloss:0.321326\n",
      "[370]\ttrain-logloss:0.26973\tvalid-logloss:0.32102\n",
      "[380]\ttrain-logloss:0.269177\tvalid-logloss:0.320779\n",
      "[390]\ttrain-logloss:0.268416\tvalid-logloss:0.320409\n",
      "[399]\ttrain-logloss:0.267887\tvalid-logloss:0.320174\n",
      "f1 score: 0.28628907458991026\n",
      "accuracy: 87.310147479639\\%\n",
      "[0]\ttrain-logloss:0.68136\tvalid-logloss:0.68177\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.584998\tvalid-logloss:0.588979\n",
      "[20]\ttrain-logloss:0.516092\tvalid-logloss:0.523696\n",
      "[30]\ttrain-logloss:0.46576\tvalid-logloss:0.476593\n",
      "[40]\ttrain-logloss:0.42795\tvalid-logloss:0.441875\n",
      "[50]\ttrain-logloss:0.3989\tvalid-logloss:0.415889\n",
      "[60]\ttrain-logloss:0.376349\tvalid-logloss:0.396279\n",
      "[70]\ttrain-logloss:0.358272\tvalid-logloss:0.381364\n",
      "[80]\ttrain-logloss:0.343911\tvalid-logloss:0.369933\n",
      "[90]\ttrain-logloss:0.333016\tvalid-logloss:0.361417\n",
      "[100]\ttrain-logloss:0.324372\tvalid-logloss:0.354729\n",
      "[110]\ttrain-logloss:0.317433\tvalid-logloss:0.349462\n",
      "[120]\ttrain-logloss:0.311694\tvalid-logloss:0.345298\n",
      "[130]\ttrain-logloss:0.306793\tvalid-logloss:0.341922\n",
      "[140]\ttrain-logloss:0.302557\tvalid-logloss:0.339106\n",
      "[150]\ttrain-logloss:0.298954\tvalid-logloss:0.336833\n",
      "[160]\ttrain-logloss:0.295588\tvalid-logloss:0.334784\n",
      "[170]\ttrain-logloss:0.292723\tvalid-logloss:0.333125\n",
      "[180]\ttrain-logloss:0.290607\tvalid-logloss:0.331911\n",
      "[190]\ttrain-logloss:0.288839\tvalid-logloss:0.330848\n",
      "[200]\ttrain-logloss:0.287295\tvalid-logloss:0.329941\n",
      "[210]\ttrain-logloss:0.285897\tvalid-logloss:0.329124\n",
      "[220]\ttrain-logloss:0.284552\tvalid-logloss:0.328385\n",
      "[230]\ttrain-logloss:0.283364\tvalid-logloss:0.32775\n",
      "[240]\ttrain-logloss:0.282132\tvalid-logloss:0.327143\n",
      "[250]\ttrain-logloss:0.280881\tvalid-logloss:0.326556\n",
      "[260]\ttrain-logloss:0.279748\tvalid-logloss:0.325988\n",
      "[270]\ttrain-logloss:0.278749\tvalid-logloss:0.325443\n",
      "[280]\ttrain-logloss:0.277837\tvalid-logloss:0.325017\n",
      "[290]\ttrain-logloss:0.276873\tvalid-logloss:0.324528\n",
      "[300]\ttrain-logloss:0.275941\tvalid-logloss:0.324099\n",
      "[310]\ttrain-logloss:0.275205\tvalid-logloss:0.323735\n",
      "[320]\ttrain-logloss:0.27456\tvalid-logloss:0.323388\n",
      "[330]\ttrain-logloss:0.273753\tvalid-logloss:0.323005\n",
      "[340]\ttrain-logloss:0.273036\tvalid-logloss:0.32265\n",
      "[350]\ttrain-logloss:0.272439\tvalid-logloss:0.322377\n",
      "[360]\ttrain-logloss:0.271521\tvalid-logloss:0.321997\n",
      "[370]\ttrain-logloss:0.27078\tvalid-logloss:0.321659\n",
      "[380]\ttrain-logloss:0.269984\tvalid-logloss:0.321326\n",
      "[390]\ttrain-logloss:0.269365\tvalid-logloss:0.321068\n",
      "[399]\ttrain-logloss:0.268903\tvalid-logloss:0.32086\n",
      "f1 score: 0.2866841536799876\n",
      "accuracy: 87.2795311339185\\%\n"
     ]
    }
   ],
   "source": [
    "# Code for cross-validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Create 2 folds\n",
    "k = 3\n",
    "kfold = StratifiedKFold(Y, k, shuffle=True, random_state=0)\n",
    "\n",
    "results = np.zeros(k)\n",
    "\n",
    "# iterate over two folds\n",
    "for i, \n",
    "for i, (train_ind, test_ind) in enumerate(kfold):\n",
    "    X_train, X_val, Y_train, Y_val = X_bag[train_ind], X_bag[test_ind], Y[train_ind], Y[test_ind]\n",
    "    gnb = GaussianNB()\n",
    "    D_train = xgb.DMatrix(X_train, label=Y_train)\n",
    "    D_val = xgb.DMatrix(X_val, label=Y_val)\n",
    "\n",
    "    weights = class_weight.compute_sample_weight('balanced', [0,1], Y_train)\n",
    "    weightss = []\n",
    "    for y in Y_train:\n",
    "        weightss.append(weights[y])\n",
    "\n",
    "    watchlist = [(D_train, 'train'), (D_val, 'valid')]\n",
    "    bst = xgb.train(params, D_train, 400, watchlist, early_stopping_rounds=50, verbose_eval=10)\n",
    "    predictions = bst.predict(data=D_val).round()\n",
    "    results[i] = f1_score(predictions, Y_val)\n",
    "    print('f1 score: {}'.format(results[i]))\n",
    "    print('accuracy: {}\\%'.format(sum(predictions==Y_val)/len(Y_val)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T13:35:03.526445Z",
     "start_time": "2018-01-29T13:35:03.481438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2882856141195729, 6.498816470590017e-06)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results), np.var(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:07:21.877609Z",
     "start_time": "2018-01-29T12:07:21.859208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T22:46:54.623967Z",
     "start_time": "2018-01-28T22:46:54.618791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 465)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bag.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
