{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "\n",
    "model = LinearSVC(dual=False,tol=1e-3, class_weight = 'balanced') #please try with different versions of gamma and 'C' parameters here\n",
    "                  \n",
    "df = pd.read_csv('telekomexportsichter11.csv')\n",
    "#df1 = pd.read_csv('telekomexportsichter12.csv')\n",
    "#df2 = pd.read_csv('telekomexportsichter13.csv')\n",
    "#df3 = pd.read_csv('telekomexportsichter14.csv')\n",
    "#df4 = pd.read_csv('telekomexportsichter15.csv')\n",
    "#df5 = pd.read_csv('telekomexportsichter16.csv')\n",
    "#df6 = pd.read_csv('telekomexportsichter17.csv')\n",
    "#df7 = pd.read_csv('telekomexportsichter18.csv')\n",
    "\n",
    "#df = df.append(df1)\n",
    "#df = df.append(df2)\n",
    "#df = df.append(df3)\n",
    "#df = df.append(df4)\n",
    "#df = df.append(df5)\n",
    "#df = df.append(df6)\n",
    "#df = df.append(df7)\n",
    "\n",
    "\n",
    "priorCases = df[(df['Tag'] == 'Prio-Fall') & (df['kind'] == 1)]['Content']\n",
    "priorCases = pd.Series.to_frame(priorCases)\n",
    "\n",
    "nonPriorCases = df[(df['Tag'] != 'Prio-Fall') & (df['kind'] == 1)]['Content']\n",
    "nonPriorCases = pd.Series.to_frame(nonPriorCases)\n",
    "\n",
    "priorCases = priorCases.assign(label = 1)\n",
    "nonPriorCases = nonPriorCases.assign(label = 0)\n",
    "#priorCases.drop(priorCases.index[priorCases['Content'].isnull()])\n",
    "#priorCases[priorCases['Content'].isnull()].head\n",
    "priorCases = priorCases.append(nonPriorCases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorCases = priorCases.drop(priorCases.index[priorCases['Content'].isnull()])\n",
    "cv = CountVectorizer(min_df = 3, max_df = 10000, ngram_range=(1, 3), lowercase =True) #change the ngram range to 5,7, maximum 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(priorCases.index[priorCases['Content'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9778869778869779\n",
      "F1\n",
      "0.6666666666666666\n",
      "0.9721518987341772\n",
      "F1\n",
      "0.6666666666666667\n",
      "0.9566326530612245\n",
      "F1\n",
      "0.5853658536585366\n",
      "0.9817767653758542\n",
      "F1\n",
      "0.7142857142857143\n",
      "0.9626168224299065\n",
      "F1\n",
      "0.5294117647058824\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits = 5, shuffle=True, random_state=0) #do not use more or less splits\n",
    "scores = []\n",
    "for train_index, test_index in skf.split(priorCases['Content'] , priorCases['label']):\n",
    "    #priorCases.loc[train_index]['Content']\n",
    "    \n",
    "    model = LinearSVC(dual=False,tol=1e-3, class_weight = 'balanced')\n",
    "    priorCases2 = priorCases.loc[train_index]\n",
    "    priorCases2 = priorCases2.drop(priorCases2.index[priorCases2['Content'].isnull()])\n",
    "    X_train_counts = cv.fit_transform(priorCases2['Content'])\n",
    "    #print(X_train_counts.shape)\n",
    "\n",
    "\n",
    "    tfidfTransform = TfidfTransformer()\n",
    "    X_Train_tfidf = tfidfTransform.fit_transform(X_train_counts)\n",
    "    #print(X_Train_tfidf.shape)\n",
    "    \n",
    "    priorCases2 = priorCases.loc[test_index]\n",
    "    priorCases2 = priorCases2.drop(priorCases2.index[priorCases2['Content'].isnull()])\n",
    "    X_test_counts = cv.transform(priorCases2['Content'])\n",
    "    #print(X_test_counts.shape)\n",
    "\n",
    "    X_test_tfidf = tfidfTransform.transform(X_test_counts)\n",
    "    #print(X_test_tfidf.shape)\n",
    "    \n",
    "    priorCases2 = priorCases.loc[train_index]\n",
    "    priorCases2 = priorCases2.drop(priorCases2.index[priorCases2['Content'].isnull()])\n",
    "    model.fit(X_Train_tfidf, priorCases2['label'])\n",
    "    \n",
    "    pred = model.predict(X_test_tfidf)\n",
    "    \n",
    "    priorCases2 = priorCases.loc[test_index]\n",
    "    priorCases2 = priorCases2.drop(priorCases2.index[priorCases2['Content'].isnull()])\n",
    "    answer = sklearn.metrics.f1_score(priorCases2['label'], pred)\n",
    "    #print(sklearn.metrics.confusion_matrix(priorCases2['label'], pred, labels=None, sample_weight=None))\n",
    "    print(np.mean(pred == priorCases2['label']))\n",
    "    print(\"F1\")\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4,suppress=True)\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Host</th>\n",
       "      <th>kind</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Content</th>\n",
       "      <th>Url</th>\n",
       "      <th>Authorid</th>\n",
       "      <th>entryid</th>\n",
       "      <th>Id</th>\n",
       "      <th>TwistId</th>\n",
       "      <th>TopicId</th>\n",
       "      <th>TopicName</th>\n",
       "      <th>IsInitialEntry</th>\n",
       "      <th>IsPrivate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.facebook.com</td>\n",
       "      <td>1</td>\n",
       "      <td>02.06.2017 08:02:03</td>\n",
       "      <td>Ich hab da mal ein Video vom neuen Smart Route...</td>\n",
       "      <td>https://www.facebook.com/deutschetelekom/posts...</td>\n",
       "      <td>11249514</td>\n",
       "      <td>0000c6fe-b9b4-4598-bebc-c29c0d3e3c5a</td>\n",
       "      <td>41401286</td>\n",
       "      <td>ee88b4f5-09fc-4b10-ba97-ef29860d1914</td>\n",
       "      <td>1</td>\n",
       "      <td>Client 388</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twitter.com</td>\n",
       "      <td>1</td>\n",
       "      <td>04.05.2017 15:23:29</td>\n",
       "      <td>RT @Telekom_hilft : meddl Leude , servus und h...</td>\n",
       "      <td>https://twitter.com/xitzjustxxxx/status/860122...</td>\n",
       "      <td>10943057</td>\n",
       "      <td>0001bfde-70e0-425f-a78a-4efb92eedeef</td>\n",
       "      <td>39942526</td>\n",
       "      <td>edb537c8-a2de-462e-9c24-b7e7c5dc8252</td>\n",
       "      <td>551631</td>\n",
       "      <td>Alle</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twitter.com</td>\n",
       "      <td>1</td>\n",
       "      <td>04.05.2017 15:42:29</td>\n",
       "      <td>@Telekom_hilft Wird WLAN eines Tages mal wiede...</td>\n",
       "      <td>https://twitter.com/tom_xcs/status/86012749461...</td>\n",
       "      <td>11050655</td>\n",
       "      <td>0005715b-7d3d-4ab2-af48-688ffacd4eb4</td>\n",
       "      <td>39943533</td>\n",
       "      <td>976fc474-3ee6-470b-893c-e72bd17b2d9f</td>\n",
       "      <td>551631</td>\n",
       "      <td>Alle</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twitter.com</td>\n",
       "      <td>1</td>\n",
       "      <td>27.06.2017 09:15:02</td>\n",
       "      <td>@Telekom_hilft ist in 01234567890 irgendeine S...</td>\n",
       "      <td>https://twitter.com/tweetkiba/status/879598934...</td>\n",
       "      <td>266235</td>\n",
       "      <td>0006432e-4d65-4197-947c-b0e6a6ee67ae</td>\n",
       "      <td>42432037</td>\n",
       "      <td>d69f0a48-08bb-4d91-9d41-4bf798bf40d1</td>\n",
       "      <td>551631</td>\n",
       "      <td>Alle</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twitter.com</td>\n",
       "      <td>1</td>\n",
       "      <td>17.05.2017 21:34:55</td>\n",
       "      <td>Hey , ich bin für #SurfenImPark :) https://t.c...</td>\n",
       "      <td>https://twitter.com/USMC_AKK/status/8649272270...</td>\n",
       "      <td>11196925</td>\n",
       "      <td>00068d65-d3df-4623-820e-8d050c1e5f01</td>\n",
       "      <td>40613868</td>\n",
       "      <td>02da374c-465b-425f-bbe3-be628295e3b4</td>\n",
       "      <td>551631</td>\n",
       "      <td>Alle</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Host  kind             Datetime  \\\n",
       "0  www.facebook.com     1  02.06.2017 08:02:03   \n",
       "1       twitter.com     1  04.05.2017 15:23:29   \n",
       "2       twitter.com     1  04.05.2017 15:42:29   \n",
       "3       twitter.com     1  27.06.2017 09:15:02   \n",
       "4       twitter.com     1  17.05.2017 21:34:55   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Ich hab da mal ein Video vom neuen Smart Route...   \n",
       "1  RT @Telekom_hilft : meddl Leude , servus und h...   \n",
       "2  @Telekom_hilft Wird WLAN eines Tages mal wiede...   \n",
       "3  @Telekom_hilft ist in 01234567890 irgendeine S...   \n",
       "4  Hey , ich bin für #SurfenImPark :) https://t.c...   \n",
       "\n",
       "                                                 Url  Authorid  \\\n",
       "0  https://www.facebook.com/deutschetelekom/posts...  11249514   \n",
       "1  https://twitter.com/xitzjustxxxx/status/860122...  10943057   \n",
       "2  https://twitter.com/tom_xcs/status/86012749461...  11050655   \n",
       "3  https://twitter.com/tweetkiba/status/879598934...    266235   \n",
       "4  https://twitter.com/USMC_AKK/status/8649272270...  11196925   \n",
       "\n",
       "                                entryid        Id  \\\n",
       "0  0000c6fe-b9b4-4598-bebc-c29c0d3e3c5a  41401286   \n",
       "1  0001bfde-70e0-425f-a78a-4efb92eedeef  39942526   \n",
       "2  0005715b-7d3d-4ab2-af48-688ffacd4eb4  39943533   \n",
       "3  0006432e-4d65-4197-947c-b0e6a6ee67ae  42432037   \n",
       "4  00068d65-d3df-4623-820e-8d050c1e5f01  40613868   \n",
       "\n",
       "                                TwistId  TopicId   TopicName  IsInitialEntry  \\\n",
       "0  ee88b4f5-09fc-4b10-ba97-ef29860d1914        1  Client 388            True   \n",
       "1  edb537c8-a2de-462e-9c24-b7e7c5dc8252   551631        Alle            True   \n",
       "2  976fc474-3ee6-470b-893c-e72bd17b2d9f   551631        Alle            True   \n",
       "3  d69f0a48-08bb-4d91-9d41-4bf798bf40d1   551631        Alle            True   \n",
       "4  02da374c-465b-425f-bbe3-be628295e3b4   551631        Alle            True   \n",
       "\n",
       "   IsPrivate  \n",
       "0      False  \n",
       "1      False  \n",
       "2      False  \n",
       "3      False  \n",
       "4      False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def preprocessing(text):\n",
    "        try:\n",
    "            text = text.lower()\n",
    "            # clean-up url\n",
    "            text = GRUBER_URLINTEXT_PAT.sub('', text)\n",
    "            # remove time\n",
    "            text = TIME_CLEAN.sub('', text)\n",
    "            # clean-up numbers\n",
    "            text = NUMBER_CLEAN.sub('', text)\n",
    "            text = PUNCT_CLEAN.sub(r'\\1\\2',text)\n",
    "            text = TWEET_CLEAN.sub('', text)\n",
    "            text = HASH_CLEAN.sub(r'\\1', text)\n",
    "            text = DASH_CLEAN.sub(r'\\1 ', text)\n",
    "            text = SPACE_CLEAN.sub(r'\\1', text)\n",
    "            text = RT_CLEAN.sub(r'', text)\n",
    "            return ' '.join([word for word in text.split(' ') if word not in stopwords]).strip()\n",
    "        except:\n",
    "            return ''\n",
    "\n",
    "def testing_main(testFileName):\n",
    "\n",
    "    frames = []\n",
    "    #for f in glob.glob(testFileName):\n",
    "    for f in glob.glob('test_data_1a_utf8_sample.csv'):\n",
    "        frames.append(pd.read_csv(f))\n",
    "    ##df = pd.read_csv('test_data_1a_utf8_sample.csv')\n",
    "    #df = pd.read_csv(testFileName)\n",
    "    raw_df = pd.concat(frames)\n",
    "    \n",
    "    df = pd.concat([raw_df[raw_df.Tag.isnull()], raw_df[raw_df.Tag=='Prio-Fall']])\n",
    "    df = df[df.kind == 1]\n",
    "\n",
    "    GRUBER_URLINTEXT_PAT = re.compile(r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?\\xab\\xbb\\u201c\\u201d\\u2018\\u2019]))')\n",
    "    NUMBER_CLEAN = re.compile(r'\\d+(:?[.,]?\\d+)*')\n",
    "    TIME_CLEAN = re.compile(r'\\d+:\\d+(?:\\s?[u]hr)?')\n",
    "    PUNCT_CLEAN = re.compile(r'(\\s?)[\\.\\,()\\[\\]\\{\\}\\^\\:\\'\\\"\\/;…/%//“=–><&]+(\\s?)')\n",
    "    DASH_CLEAN = re.compile(r'([^et])[-]')\n",
    "    TWEET_CLEAN = re.compile(r'@\\w+')\n",
    "    HASH_CLEAN = re.compile(r'#(\\w+)')\n",
    "    SPACE_CLEAN = re.compile(r'(\\s)\\s+')\n",
    "    RT_CLEAN = re.compile(r'^rt\\b')\n",
    "\n",
    "    with open('./stopwords-de.txt') as f:\n",
    "        stopwords = f.read().split('\\n')\n",
    "        \n",
    "    documents = [] # Content\n",
    "    docs = [] # Content through spacy\n",
    "    labels = [] # SichterName\n",
    "    tags = [] # Tag\n",
    "\n",
    "    for (idx, row) in tqdm(df.iterrows()):\n",
    "        labels.append(row.SichterName)\n",
    "        documents.append(preprocessing(row.Content))\n",
    "    #     docs.append([token for token in nlp(documents[-1])])\n",
    "        tags.append(str(row.Tag))\n",
    "    \n",
    "    \n",
    "    # Save processed rows\n",
    "    pickle.dump(documents, open('documents.pl', 'wb'))\n",
    "    pickle.dump(labels, open('labels.pl', 'wb'))\n",
    "    pickle.dump(tags, open('tags.pl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
