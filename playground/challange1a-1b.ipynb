{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:17:11.800574Z",
     "start_time": "2018-01-29T15:17:10.937919Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "pd.set_option(\"display.max_rows\", 30)\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.max_colwidth\", 1000)\n",
    "pd.set_option(\"display.width\", 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:17:12.047933Z",
     "start_time": "2018-01-29T15:17:11.803757Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "np.set_printoptions(precision=4,suppress=True)\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:46:20.928533Z",
     "start_time": "2018-01-29T15:46:20.493250Z"
    }
   },
   "outputs": [],
   "source": [
    "documents = pickle.load(open('documents.pl','rb'))\n",
    "labels = pickle.load(open('labels.pl','rb'))\n",
    "tags = pickle.load(open('tags.pl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-26T14:23:41.956631Z",
     "start_time": "2018-01-26T14:23:41.954043Z"
    }
   },
   "source": [
    "# Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:17:40.904710Z",
     "start_time": "2018-01-29T15:17:24.498Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# create lemma lists filter punctuation and numbers\n",
    "# from spacy\n",
    "lemmas = [word.lemma_ for words in docs for word in words if word.pos_ not in ['PUNCT','NUM']]\n",
    "counts = Counter(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:17:40.907577Z",
     "start_time": "2018-01-29T15:17:25.026Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lemma_df = pd.DataFrame.from_dict(counts, orient='index')\n",
    "lemma_df.sort_values(by=0,ascending=False).head(50).plot(kind='bar', figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T13:29:21.615327Z",
     "start_time": "2018-01-29T13:29:21.498841Z"
    }
   },
   "outputs": [],
   "source": [
    "counts = Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:19:40.516259Z",
     "start_time": "2018-01-29T12:17:54.154Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmas = [len(words) for words in documents]\n",
    "word_counts = Counter(lemmas)\n",
    "\n",
    "lemma_df = pd.DataFrame.from_dict(word_counts, orient='index')\n",
    "a = lemma_df.sort_values(by=0,ascending=False).head(50).plot(kind='bar', figsize=(20,10))\n",
    "a.set_title('number of words per row')\n",
    "a.set_ylabel('number of rows')\n",
    "a.set_xlabel('number of words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:19:40.518420Z",
     "start_time": "2018-01-29T12:17:54.380Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmas = ([len(document) for document in documents])\n",
    "word_counts = Counter(lemmas)\n",
    "\n",
    "lemma_df = pd.DataFrame.from_dict(word_counts, orient='index')\n",
    "a = lemma_df.sort_values(by=0,ascending=False).head(50).plot(kind='bar', figsize=(20,10))\n",
    "a.set_title('number of characters per row')\n",
    "a.set_ylabel('number of rows')\n",
    "a.set_xlabel('number of words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:19:40.520644Z",
     "start_time": "2018-01-29T12:17:54.619Z"
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "cloud = WordCloud(width=1440, height=1080).generate(\" \".join([word.lemma_ for doc in docs for word in doc]))\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.imshow(cloud)\n",
    "plt.title('Most common lemmas')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:19:40.523041Z",
     "start_time": "2018-01-29T12:17:55.114Z"
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "cloud = WordCloud(width=1440, height=1080).generate(\" \".join([word.lemma_ for doc in docs for word in doc if word.lemma_.lower() not in stopwords]))\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.imshow(cloud)\n",
    "plt.title('Most common lemmas without stopwords')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:19:40.524473Z",
     "start_time": "2018-01-29T12:17:55.438Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qmarks = np.mean(df.Content.apply(lambda x: '?' in x))\n",
    "math = np.mean(df.Content.apply(lambda x: '€' in x))\n",
    "fullstop = np.mean(df.Content.apply(lambda x: '.' in x))\n",
    "capital_first = np.mean(df.Content.apply(lambda x: x[0].isupper()))\n",
    "capitals = np.mean(df.Content.apply(lambda x: max([y.isupper() for y in x.split(' ')])))\n",
    "numbers = np.mean(df.Content.apply(lambda x: max([y.isdigit() for y in x])))\n",
    "\n",
    "print('Rows with question marks: {:.2f}%'.format(qmarks * 100))\n",
    "print('Rows with €: {:.2f}%'.format(math * 100))\n",
    "print('Rows with full stops: {:.2f}%'.format(fullstop * 100))\n",
    "print('Rows with capitalised first letters: {:.2f}%'.format(capital_first * 100))\n",
    "print('Rows with capital letters: {:.2f}%'.format(capitals * 100))\n",
    "print('Rows with numbers: {:.2f}%'.format(numbers * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:28:45.748780Z",
     "start_time": "2018-01-29T12:28:45.740420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{label for label in labels if type(label) is str}\n",
    "len([label for label in labels if type(label) is str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T12:32:33.656946Z",
     "start_time": "2018-01-29T12:32:33.651348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prio distrib.: 0.10005817335660268\n"
     ]
    }
   ],
   "source": [
    "print('prio distrib.: {}'.format(sum(tags)/len(tags)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:21:50.141188Z",
     "start_time": "2018-01-29T15:21:50.126810Z"
    }
   },
   "outputs": [],
   "source": [
    "# bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "CountVectorizer()\n",
    "BoW = CountVectorizer(documents, stop_words=stopwords, strip_accents='unicode', ngram_range=(1,3), min_df=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:22:30.472423Z",
     "start_time": "2018-01-29T15:21:51.849798Z"
    }
   },
   "outputs": [],
   "source": [
    "X_bag = BoW.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:22:30.494775Z",
     "start_time": "2018-01-29T15:22:30.480272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 367992)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bag[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:22:30.526338Z",
     "start_time": "2018-01-29T15:22:30.497090Z"
    }
   },
   "outputs": [],
   "source": [
    "Y = np.array(np.array(tags)=='Prio-Fall', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:22:30.557058Z",
     "start_time": "2018-01-29T15:22:30.531060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14504915987966835"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y)/len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T15:22:43.272250Z",
     "start_time": "2018-01-29T15:22:43.263797Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Set our parameters for xgboost\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['max_delta_step'] = 1\n",
    "params['eta'] = 0.02\n",
    "params['max_depth'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-29T15:22:56.947Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.685985\tvalid-logloss:0.686139\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.619309\tvalid-logloss:0.621231\n",
      "[20]\ttrain-logloss:0.562046\tvalid-logloss:0.565916\n",
      "[30]\ttrain-logloss:0.513792\tvalid-logloss:0.519646\n",
      "[40]\ttrain-logloss:0.473825\tvalid-logloss:0.481173\n",
      "[50]\ttrain-logloss:0.441473\tvalid-logloss:0.450276\n",
      "[60]\ttrain-logloss:0.416329\tvalid-logloss:0.426366\n",
      "[70]\ttrain-logloss:0.396462\tvalid-logloss:0.407615\n",
      "[80]\ttrain-logloss:0.380974\tvalid-logloss:0.393184\n",
      "[90]\ttrain-logloss:0.368871\tvalid-logloss:0.382121\n",
      "[100]\ttrain-logloss:0.359491\tvalid-logloss:0.37359\n",
      "[110]\ttrain-logloss:0.352182\tvalid-logloss:0.367058\n",
      "[120]\ttrain-logloss:0.346345\tvalid-logloss:0.361976\n",
      "[130]\ttrain-logloss:0.341422\tvalid-logloss:0.357792\n",
      "[140]\ttrain-logloss:0.337484\tvalid-logloss:0.354511\n",
      "[150]\ttrain-logloss:0.334163\tvalid-logloss:0.351858\n",
      "[160]\ttrain-logloss:0.331348\tvalid-logloss:0.349727\n",
      "[170]\ttrain-logloss:0.329069\tvalid-logloss:0.347952\n",
      "[180]\ttrain-logloss:0.327067\tvalid-logloss:0.346432\n",
      "[190]\ttrain-logloss:0.325286\tvalid-logloss:0.345145\n",
      "[200]\ttrain-logloss:0.323653\tvalid-logloss:0.344023\n",
      "[210]\ttrain-logloss:0.322137\tvalid-logloss:0.343018\n",
      "[220]\ttrain-logloss:0.320917\tvalid-logloss:0.342211\n",
      "[230]\ttrain-logloss:0.319634\tvalid-logloss:0.341336\n",
      "[240]\ttrain-logloss:0.318578\tvalid-logloss:0.340722\n",
      "[250]\ttrain-logloss:0.317416\tvalid-logloss:0.340054\n",
      "[260]\ttrain-logloss:0.316333\tvalid-logloss:0.33948\n",
      "[270]\ttrain-logloss:0.315198\tvalid-logloss:0.338821\n",
      "[280]\ttrain-logloss:0.314304\tvalid-logloss:0.338385\n",
      "[290]\ttrain-logloss:0.313629\tvalid-logloss:0.338024\n",
      "[300]\ttrain-logloss:0.312936\tvalid-logloss:0.337662\n",
      "[310]\ttrain-logloss:0.312255\tvalid-logloss:0.337278\n",
      "[320]\ttrain-logloss:0.311732\tvalid-logloss:0.337005\n",
      "[330]\ttrain-logloss:0.311182\tvalid-logloss:0.3367\n",
      "[340]\ttrain-logloss:0.310699\tvalid-logloss:0.33644\n",
      "[350]\ttrain-logloss:0.310144\tvalid-logloss:0.336181\n",
      "[360]\ttrain-logloss:0.309646\tvalid-logloss:0.335906\n",
      "[370]\ttrain-logloss:0.309195\tvalid-logloss:0.335675\n",
      "[380]\ttrain-logloss:0.308714\tvalid-logloss:0.335433\n",
      "[390]\ttrain-logloss:0.308289\tvalid-logloss:0.335233\n",
      "[399]\ttrain-logloss:0.307918\tvalid-logloss:0.335067\n",
      "f1 score: 0.2121014964216005\n",
      "accuracy: 86.67216948686202\\%\n",
      "[0]\ttrain-logloss:0.685969\tvalid-logloss:0.686105\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.619383\tvalid-logloss:0.620936\n",
      "[20]\ttrain-logloss:0.562018\tvalid-logloss:0.565381\n",
      "[30]\ttrain-logloss:0.513906\tvalid-logloss:0.518815\n",
      "[40]\ttrain-logloss:0.473963\tvalid-logloss:0.480348\n",
      "[50]\ttrain-logloss:0.44156\tvalid-logloss:0.449584\n",
      "[60]\ttrain-logloss:0.415968\tvalid-logloss:0.425592\n",
      "[70]\ttrain-logloss:0.395839\tvalid-logloss:0.407024\n",
      "[80]\ttrain-logloss:0.3801\tvalid-logloss:0.392686\n",
      "[90]\ttrain-logloss:0.367868\tvalid-logloss:0.381794\n",
      "[100]\ttrain-logloss:0.358358\tvalid-logloss:0.373508\n",
      "[110]\ttrain-logloss:0.35098\tvalid-logloss:0.367243\n",
      "[120]\ttrain-logloss:0.345107\tvalid-logloss:0.362327\n",
      "[130]\ttrain-logloss:0.340261\tvalid-logloss:0.358324\n"
     ]
    }
   ],
   "source": [
    "# Code for cross-validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Create 2 folds\n",
    "k = 3\n",
    "kfold = StratifiedKFold(Y, k, shuffle=True, random_state=0)\n",
    "\n",
    "results = np.zeros(k)\n",
    "\n",
    "# iterate over two folds\n",
    "for i, (train_ind, test_ind) in enumerate(kfold):\n",
    "    X_train, X_val, Y_train, Y_val = X_bag[train_ind], X_bag[test_ind], Y[train_ind], Y[test_ind]\n",
    "    \n",
    "    D_train = xgb.DMatrix(X_train, label=Y_train)\n",
    "    D_val = xgb.DMatrix(X_val, label=Y_val)\n",
    "\n",
    "    weights = class_weight.compute_sample_weight('balanced', [0,1], Y_train)\n",
    "    weightss = []\n",
    "    for y in Y_train:\n",
    "        weightss.append(weights[y])\n",
    "\n",
    "    watchlist = [(D_train, 'train'), (D_val, 'valid')]\n",
    "    bst = xgb.train(params, D_train, 400, watchlist, early_stopping_rounds=50, verbose_eval=10)\n",
    "    predictions = bst.predict(data=D_val).round()\n",
    "    results[i] = f1_score(predictions, Y_val)\n",
    "    print('f1 score: {}'.format(results[i]))\n",
    "    print('accuracy: {}\\%'.format(sum(predictions==Y_val)/len(Y_val)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T13:35:03.526445Z",
     "start_time": "2018-01-29T13:35:03.481438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2882856141195729, 6.498816470590017e-06)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results), np.var(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
